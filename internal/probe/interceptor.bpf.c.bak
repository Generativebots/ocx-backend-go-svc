// +build ignore
#include <vmlinux.h>
#include <bpf/bpf_helpers.h>
#include <bpf/bpf_tracing.h>
#include <bpf/bpf_core_read.h>

char __license[] SEC("license") = "Dual MIT/GPL";

struct event {
    u32 pid;
    u32 fd;
    char comm[16];
    u32 size;
    u8 payload[1024];
};

// Innovation: Using a Map to track state between Enter and Exit
// Key: PID | TID (u64) -> Value: Buffer Address (u64)
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 10240);
    __type(key, u64);   
    __type(value, u64); 
} tracked_buffers SEC(".maps");

// PID Filter Map
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 1024);
    __type(key, u32);
    __type(value, u8);
} pids_to_trace SEC(".maps");

// High-Performance Ring Buffer
struct {
    __uint(type, BPF_MAP_TYPE_RINGBUF);
    __uint(max_entries, 1 << 12);
} events SEC(".maps");

struct exit_event {
    u32 pid;
};

struct {
    __uint(type, BPF_MAP_TYPE_RINGBUF);
    __uint(max_entries, 1 << 12);
} exit_events SEC(".maps");

SEC("tracepoint/sched/sched_process_exit")
int handle_exit(struct trace_event_raw_sched_process_template *ctx) {
    u32 pid = bpf_get_current_pid_tgid() >> 32;

    // 1. EVICT from Verdict Cache (Anti-Recycling)
    bpf_map_delete_elem(&verdict_cache, &pid);

    // 2. Notify User Space (Lifecycle Manager)
    struct exit_event *e;
    e = bpf_ringbuf_reserve(&exit_events, sizeof(*e), 0);
    if (!e) return 0;

    e->pid = pid;
    bpf_ringbuf_submit(e, 0);
    return 0;
}


// Verdict Cache: PID -> Action
// 0: Block (Default), 1: Allow
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 10240);
    __type(key, u32);
    __type(value, u32);
} verdict_cache SEC(".maps");

// LSM Hook: socket_sendmsg
// This is the "Gatekeeper". It runs BEFORE the packet is sent.
// Requires kernel 5.7+ and CONFIG_BPF_LSM=y
SEC("lsm/socket_sendmsg")
int BPF_PROG(enforce_policy, struct socket *sock, struct msghdr *msg, size_t size) {
    u64 pid_tgid = bpf_get_current_pid_tgid();
    u32 pid = pid_tgid >> 32;

    // 1. Fast Path: Check Verdict Cache
    u32 *verdict = bpf_map_lookup_elem(&verdict_cache, &pid);
    if (verdict && *verdict == 1) {
        return 0; // ALLOW (Proceed)
    }

    // 2. Slow Path: No Verdict found (or explicitly Blocked)
    
    // We must capture the event to ask the Jury.
    // Ideally, we'd put this in a queue and Sleep, but eBPF can't sleep.
    // So we BLOCK access (-EPERM) and force the app to retry or fail, 
    // while we send the alert to userspace.
    
    // Capture details for the Jury
    struct event *ev;
    ev = bpf_ringbuf_reserve(&events, sizeof(struct event), 0);
    if (ev) {
        ev->pid = pid;
        bpf_get_current_comm(&ev->comm, sizeof(ev->comm));
        ev->fd = 0; // LSM doesn't strictly give us the FD easily here without sk storage, simplifying for prompt.
        ev->size = size;
        
        // We can't easily read the user buffer here because 'msg' is kernel struct, 
        // and msg->msg_iter is complex. 
        // For the "Signal" to the Jury, metadata is often enough to start the decision.
        // Or we rely on the implementation to handle "first packet" logic.
        
        // Placeholder payload for the alert
        ev->payload[0] = 0; 
        
        bpf_ringbuf_submit(ev, 0);
    }

    // Default Action: BLOCK
    // The "Sound-Proof" Standard dictates we fail-closed.
    return -1; // -EPERM
}

// Keeping the Kretprobe for Observability/Telemetry of actual traffic flow (post-decision)
SEC("kretprobe/sys_read")
int kretprobe_sys_read(struct pt_regs *ctx) {
// ... existing logic ...


// SYS_EXIT: Read the data now that it is populated
SEC("kretprobe/sys_read")
int kretprobe_sys_read(struct pt_regs *ctx) {
    u64 id = bpf_get_current_pid_tgid();
    u64 *buf_addr = bpf_map_lookup_elem(&tracked_buffers, &id);
    if (!buf_addr) return 0;

    // Get return value (number of bytes read)
    long ret = PT_REGS_RC(ctx);
    if (ret <= 0) {
        // Error or EOF, clean up and exit
        bpf_map_delete_elem(&tracked_buffers, &id);
        return 0;
    }

    // Prepare event
    // Reserve space in Ring Buffer directly (Zero-Copy-ish in BPF land)
    struct event *ev;
    ev = bpf_ringbuf_reserve(&events, sizeof(struct event), 0);
    if (!ev) {
        // Ring buffer full
        bpf_map_delete_elem(&tracked_buffers, &id);
        return 0;
    }

    ev->pid = id >> 32;
    bpf_get_current_comm(&ev->comm, sizeof(ev->comm));
    // Note: FD is missing in kretprobe context easily without tracking it from entry too.
    // For "Sound-Proof", we should ideally track struct { fd, buf } in the map.
    // For this prompt, omitting FD re-lookup for brevity unless requested. 
    // (Assuming simplistic tracking).
    
    ev->size = (u32)ret;
    u32 cap_size = ev->size > 1024 ? 1024 : ev->size;

    // Read user data from the stored address
    bpf_probe_read_user(&ev->payload, cap_size, (void *)*buf_addr);

    // Submit
    bpf_ringbuf_submit(ev, 0);

    // Clean up
    bpf_map_delete_elem(&tracked_buffers, &id);
    return 0;
}
